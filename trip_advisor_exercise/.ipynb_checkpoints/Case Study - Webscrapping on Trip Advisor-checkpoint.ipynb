{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/FoKB5Z5.png\" align=\"left\" width=\"300\" height=\"250\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Code: J620-002-4:2020 \n",
    "\n",
    "## Program Name: FRONT-END SOFTWARE DEVELOPMENT\n",
    "\n",
    "## Title :  Case Study - Webscrapping on Trip Advisor\n",
    "\n",
    "#### Name: \n",
    "\n",
    "#### IC Number:\n",
    "\n",
    "#### Date : 4/7/2023\n",
    "\n",
    "#### Introduction : \n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion :\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction: Use Selenium and Beautiful Soup to extract the first 5 comments and their titles from the trip advisor link.\n",
    "\n",
    "Url: https://www.tripadvisor.com/Airline_Review-d8729220-Reviews-AirAsia-AirAsia-Berhad-Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementNotInteractableException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\ACER\\Desktop\\ChromeDriver\\chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver.get(\"https://www.tripadvisor.com/Airline_Review-d8729220-Reviews-AirAsia-AirAsia-Berhad-Malaysia\")\n",
    "time.sleep(5)\n",
    "\n",
    "comments = []\n",
    "for page in range(1, 6):\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    soup_list = soup.find_all(\"div\", attrs={\"class\":\"WAllg _T\"})\n",
    "        \n",
    "    for items in range(len(soup_list)):\n",
    "        header = soup_list[items].find(\"a\", attrs={\"class\":\"Qwuub\"}).text\n",
    "        button = driver.find_element(By.LINK_TEXT, \"Read more\")\n",
    "        if button.is_displayed() and button.is_enabled():\n",
    "            button.click()\n",
    "            body = soup_list[items].find('div', attrs={'class':'fIrGe _T'}).text\n",
    "            comment = f\"{header}:\\n\\t{body}\"\n",
    "            comments.append(comment)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if page == 1:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"component_1\"]/div/div[5]/div/div/div/div[2]/div[1]/div[2]/div/div[8]/div/a').click()\n",
    "        time.sleep(5)\n",
    "    elif page == 5:\n",
    "        break\n",
    "    else:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"component_1\"]/div/div[5]/div/div/div/div[2]/div[1]/div[2]/div/div[8]/div/a[2]').click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "for i, comment in enumerate(comments):\n",
    "    print(f\"Comment {i+1}\\n{comment}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://medium.com/ymedialabs-innovation/web-scraping-using-beautiful-soup-and-selenium-for-dynamic-page-2f8ad15efe25\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
