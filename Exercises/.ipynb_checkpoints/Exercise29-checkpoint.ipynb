{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/FoKB5Z5.png\" align=\"left\" width=\"300\" height=\"250\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Code: J620-002-4:2020 \n",
    "\n",
    "## Program Name: FRONT-END SOFTWARE DEVELOPMENT\n",
    "\n",
    "## Title : Exe29 - Neural Network Exercise 1\n",
    "\n",
    "#### Name: Chong Mun Chen\n",
    "\n",
    "#### IC Number: 960327-07-5097\n",
    "\n",
    "#### Date : 31/7/2023\n",
    "\n",
    "#### Introduction : Practising on this exercise with Neural Network learning model.\n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion : Succeeded in training a Multi-Layer Perceptron Classifier with a high accuracy score.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Introduction\n",
    "\n",
    "This exercise is adapted from https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use SciKit Learn's built in Breast Cancer Data Set which has several features of tumors with a labeled class indicating whether the tumor was Malignant or Benign. We will try to create a neural network model that can take in these features and attempt to predict malignant or benign labels for tumors it has not seen before. Let's go ahead and start by getting the data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is like a dictionary, it contains a description of the data and the features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the attributes in the dataset\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the total instances and number of features\n",
    "\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the data (x) and labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    " \n",
    "Let's split our data into training and testing sets, this is done easily with SciKit Learn's train_test_split function from model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    " \n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results. There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the StandardScalar library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train_transformed = sc.transform(X_train)\n",
    "X_test_transformed = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    " \n",
    "Now it is time to train our model. SciKit Learn makes this incredibly easy, by using estimator objects. In this case we will import our estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the model, there are a lot of parameters you can choose to define and customize here, we will only define the hidden_layer_sizes. For this parameter you pass in a tuple consisting of the number of neurons you want at each layer, where the nth entry in the tuple represents the number of neurons in the nth layer of the MLP model. There are many ways to choose these numbers, but for simplicity we will choose 3 layers with the same number of neurons as there are features in our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Multilayerperceptron classifier and call it mlp\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (30, 30, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been made we can fit the training data to our model, remember that this data has already been processed and scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(30, 30, 30))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(30, 30, 30))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you see in the output? What does it tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 hidden layers with 30 neurons each. The number of neurons in a layer is dependent on the number of features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation\n",
    " \n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test_transformed)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  4]\n",
      " [ 0 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        61\n",
      "           1       0.95      1.00      0.98        82\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.98      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** what conclusion can you make from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can conclude that my model has high precision, recall, and F1-score for the two outputs, False and True, and an accuracy of 97% to be able to make correct predictions for the negative and positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and biases\n",
    "\n",
    "The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
    "\n",
    "To extract the MLP weights and biases after training your model, you use its public attributes coefs_ and intercepts_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1348932 , -0.26243641, -0.13492215, -0.20923182, -0.04909902,\n",
       "         0.11550678, -0.08054107,  0.29168487,  0.14553945, -0.12810964,\n",
       "        -0.1472266 ,  0.18486843, -0.12295266,  0.30723479, -0.20584349,\n",
       "         0.30581277,  0.1480443 , -0.1741783 , -0.28915813,  0.02187519,\n",
       "         0.26217966,  0.02806523, -0.24489932,  0.27378627,  0.17576296,\n",
       "        -0.15748238,  0.22920037,  0.09730606,  0.23248364, -0.14839052],\n",
       "       [ 0.20330617, -0.30123041, -0.12612949,  0.21585199, -0.18347869,\n",
       "        -0.05822357,  0.09896193,  0.31184303, -0.22004983, -0.29374942,\n",
       "         0.16367996,  0.23961324, -0.06863384,  0.02124192, -0.21554987,\n",
       "        -0.19529145,  0.25073918,  0.25729685,  0.22818582, -0.16684243,\n",
       "        -0.09770845,  0.02945036, -0.37682906, -0.01773573,  0.00567062,\n",
       "        -0.24167704,  0.06469813, -0.09513673,  0.009529  ,  0.34533288],\n",
       "       [-0.02966327, -0.23266791,  0.11121862,  0.11956834, -0.34718341,\n",
       "        -0.38615165,  0.23787106, -0.05344889,  0.3161587 , -0.13118013,\n",
       "         0.07776169, -0.29184155,  0.39052985,  0.02296943,  0.10667326,\n",
       "         0.00150195, -0.10493366, -0.17930562, -0.334441  ,  0.09639755,\n",
       "        -0.24291226,  0.07379263,  0.02572206, -0.21411073, -0.25649903,\n",
       "         0.17897422,  0.00522721,  0.1529925 , -0.02137358,  0.26487154],\n",
       "       [-0.35130624, -0.26532139,  0.1372096 ,  0.13133109,  0.03618637,\n",
       "         0.10949562,  0.1407567 , -0.12431141, -0.14184982, -0.24942818,\n",
       "         0.20073686,  0.14902508,  0.25807483, -0.15822376,  0.17954898,\n",
       "        -0.12896823, -0.07551526, -0.18441668,  0.15730761,  0.00871332,\n",
       "         0.22281397,  0.11499087, -0.26789647, -0.18627402, -0.23236063,\n",
       "         0.10514233, -0.01362921,  0.30283649,  0.22459089,  0.09169089],\n",
       "       [ 0.0325747 ,  0.14446151, -0.03601786, -0.24947408,  0.17942524,\n",
       "         0.07421186, -0.03422547,  0.01945543,  0.16294585, -0.11105627,\n",
       "         0.25194305, -0.1286166 , -0.24332073,  0.20037835,  0.179339  ,\n",
       "         0.34729439,  0.04270064, -0.1137322 ,  0.11584947, -0.0452082 ,\n",
       "         0.32255099, -0.24121492, -0.28558454,  0.04633266,  0.06119955,\n",
       "         0.19276447, -0.28151989,  0.15002043, -0.14671521,  0.22497677],\n",
       "       [-0.05834454,  0.08331048,  0.13813984,  0.01433212, -0.12677588,\n",
       "         0.28418293,  0.09942651, -0.29956742, -0.28509659,  0.24455263,\n",
       "         0.28389594,  0.11822242,  0.12390214,  0.22407034,  0.23055211,\n",
       "         0.0172317 , -0.12712498, -0.23541543,  0.02699922,  0.06720298,\n",
       "         0.08619353,  0.03686355, -0.24702428, -0.21806396, -0.30661152,\n",
       "         0.05021169, -0.20951381,  0.02042685, -0.14500912,  0.01224342],\n",
       "       [-0.22100666, -0.24937694,  0.19349765, -0.16127541, -0.30383047,\n",
       "        -0.29210138, -0.14159567,  0.3625828 , -0.14726122,  0.21208962,\n",
       "         0.04197656, -0.03828547,  0.30483771, -0.37637378,  0.1296883 ,\n",
       "        -0.11380595,  0.05649369, -0.28439209, -0.0425688 ,  0.24306163,\n",
       "         0.00566552, -0.09107169, -0.20780983, -0.20510022,  0.11369955,\n",
       "        -0.24198589,  0.07886702,  0.27495393,  0.12694289,  0.17932265],\n",
       "       [ 0.05671928,  0.07155631,  0.3490182 , -0.21779945, -0.08634927,\n",
       "        -0.31442583, -0.0060941 ,  0.21519429,  0.00470968,  0.12532584,\n",
       "         0.03541715,  0.23436755,  0.27638477, -0.20259736,  0.04829475,\n",
       "        -0.02110726,  0.20802132,  0.20239759, -0.24323788,  0.21271323,\n",
       "         0.07026784,  0.27794493, -0.2580821 ,  0.07889954,  0.11182325,\n",
       "        -0.02554743,  0.23844238,  0.13960071, -0.04201147, -0.00242   ],\n",
       "       [ 0.0022004 ,  0.02512611,  0.16101414,  0.19455232, -0.19102681,\n",
       "        -0.04168047,  0.22933982, -0.12323288, -0.04618727, -0.34033469,\n",
       "         0.20518743,  0.02952121, -0.25088086, -0.01493642, -0.19893582,\n",
       "         0.00542919,  0.40469846,  0.32052351, -0.03381339,  0.15210732,\n",
       "         0.05435991,  0.23566735,  0.04903069,  0.17523492, -0.08690346,\n",
       "         0.28666746, -0.16498465, -0.26656285,  0.04158486,  0.1932202 ],\n",
       "       [ 0.2530771 ,  0.0218409 , -0.12599349,  0.08995315, -0.00716045,\n",
       "         0.15064183,  0.12570859, -0.32023675, -0.01967962,  0.36466008,\n",
       "        -0.13947784, -0.01818005, -0.20115867, -0.30285488,  0.06199608,\n",
       "         0.18330676,  0.37976676, -0.25792839,  0.36342269,  0.2720879 ,\n",
       "         0.02109562, -0.26974497, -0.25876498, -0.02355685, -0.20256415,\n",
       "        -0.27385506, -0.35839493,  0.04836482, -0.25870087,  0.19819706],\n",
       "       [-0.49617666, -0.27157241, -0.0910679 ,  0.18739304, -0.26815791,\n",
       "        -0.33541776,  0.00157149, -0.12697266, -0.03179329, -0.19027122,\n",
       "        -0.04352674,  0.21529862, -0.17923224, -0.2717663 , -0.47116695,\n",
       "         0.10012232,  0.14253113, -0.34510895,  0.13698527,  0.28616955,\n",
       "         0.34709581, -0.22627612, -0.0954155 ,  0.28859363,  0.32447332,\n",
       "         0.07188692, -0.05750958,  0.00329405, -0.11384738,  0.25773631],\n",
       "       [ 0.03440189, -0.37981748,  0.33483853,  0.00290737,  0.11429407,\n",
       "         0.01729117,  0.31259023, -0.27378725,  0.30619808, -0.32486477,\n",
       "        -0.0319327 ,  0.19701243, -0.01336721,  0.30161011, -0.18482541,\n",
       "         0.05165954,  0.19386907,  0.32725314,  0.19997199, -0.29424995,\n",
       "        -0.26745076,  0.01369122,  0.22193892,  0.03165216, -0.02336223,\n",
       "         0.03441749, -0.19374839, -0.18296771, -0.21180074, -0.22863222],\n",
       "       [-0.23563017, -0.22984566, -0.19639045,  0.1375961 , -0.07963125,\n",
       "         0.03179446,  0.39155469, -0.03714985, -0.16477956,  0.08218674,\n",
       "         0.25872975,  0.11327587,  0.26427091, -0.23288428,  0.08614858,\n",
       "         0.29437504, -0.14011482, -0.02217697, -0.24252791, -0.20554592,\n",
       "         0.0400805 , -0.26160006, -0.21061601, -0.25998435, -0.10507158,\n",
       "         0.22614067, -0.41601019, -0.23693575, -0.11315666, -0.08596819],\n",
       "       [-0.26408619,  0.07126358, -0.14675286, -0.34640933, -0.11453774,\n",
       "         0.17411717,  0.41626772,  0.20182602, -0.0141122 , -0.32302861,\n",
       "         0.01925746,  0.2589332 , -0.02863917,  0.16843138, -0.40394229,\n",
       "         0.09476282,  0.09036677, -0.31154248,  0.18352049,  0.02175086,\n",
       "         0.17247609,  0.21388726,  0.06949119,  0.19238139,  0.22060832,\n",
       "        -0.26434086, -0.31291812, -0.02620627, -0.40736942,  0.20462453],\n",
       "       [-0.24012266,  0.14876656, -0.17003983,  0.18079888, -0.15366869,\n",
       "         0.09118072, -0.26638235,  0.04255545, -0.30733716,  0.27626977,\n",
       "        -0.02832238, -0.13510113,  0.30268306,  0.2260021 ,  0.16527069,\n",
       "         0.10413066, -0.25119489,  0.21913472,  0.0502862 , -0.04082711,\n",
       "         0.09550449,  0.1510834 , -0.15477136, -0.03259441, -0.24771945,\n",
       "        -0.2489391 ,  0.14744374, -0.21219844, -0.28499058, -0.22156172],\n",
       "       [ 0.16931684,  0.06863892,  0.00661968,  0.14750681,  0.25012343,\n",
       "         0.39628162, -0.36263383, -0.17404281, -0.21248442, -0.01985148,\n",
       "         0.192415  , -0.21094452, -0.25720006, -0.10501555,  0.13410187,\n",
       "         0.1347209 , -0.21649252, -0.17356295, -0.05105487,  0.08025713,\n",
       "         0.1489216 ,  0.12586657, -0.07379762,  0.15959065,  0.16045519,\n",
       "         0.28592533,  0.28121457, -0.15390159,  0.30053087,  0.13643037],\n",
       "       [-0.29485581, -0.11478527,  0.34076801, -0.40339168, -0.23591057,\n",
       "         0.20091101,  0.24071742,  0.24842675, -0.13922148, -0.20949902,\n",
       "        -0.18254336, -0.0577244 , -0.20061267,  0.03797061,  0.14829375,\n",
       "        -0.22926887, -0.17020435, -0.15743836, -0.23549501, -0.29369983,\n",
       "         0.13955519, -0.18103751, -0.02316947,  0.26533216,  0.09974025,\n",
       "        -0.11834731, -0.23771342, -0.25693257, -0.25484518,  0.08541951],\n",
       "       [ 0.01148658,  0.02170944,  0.22677556, -0.30089227,  0.27815984,\n",
       "        -0.15031822,  0.18752544,  0.15582195,  0.18810647,  0.07837618,\n",
       "        -0.17357261, -0.20309472,  0.38037423,  0.12014418,  0.21777722,\n",
       "         0.21606522, -0.20064182, -0.30104604,  0.25593216,  0.05678596,\n",
       "        -0.0794262 ,  0.15473963,  0.00058601, -0.18355013, -0.21556448,\n",
       "        -0.14965393, -0.0818304 ,  0.21320448,  0.12268804, -0.17041598],\n",
       "       [ 0.11675406, -0.03362271,  0.08972591,  0.06042926,  0.04973655,\n",
       "         0.20515721, -0.24323814, -0.29504984,  0.02748051,  0.21412276,\n",
       "        -0.13470006,  0.13361007,  0.22286047, -0.18322283, -0.32879338,\n",
       "         0.09768272, -0.05225894,  0.1307642 ,  0.14555641,  0.03393802,\n",
       "         0.26880371, -0.098869  ,  0.31606467, -0.09039256,  0.09793338,\n",
       "         0.12314825,  0.17219544, -0.3130604 , -0.15956132, -0.17814557],\n",
       "       [ 0.22376187,  0.02311553,  0.24287819,  0.28282708,  0.35779303,\n",
       "         0.39728622, -0.07782399, -0.14442856,  0.1128761 , -0.27642331,\n",
       "         0.11723185, -0.13592883,  0.01430891, -0.14831102, -0.22481781,\n",
       "         0.18868324, -0.28153438, -0.09393282, -0.03064886, -0.01490756,\n",
       "        -0.40055064, -0.43481661, -0.04015961,  0.08510197,  0.12974858,\n",
       "         0.01123995,  0.25183654, -0.27819706,  0.13176981,  0.10629662],\n",
       "       [-0.0849746 , -0.1640248 , -0.24294452, -0.34941834, -0.09051427,\n",
       "         0.07800335,  0.20422193,  0.18834375,  0.28369374, -0.04784186,\n",
       "         0.14051738,  0.09083173, -0.17267286, -0.02661916,  0.19093794,\n",
       "         0.09185438, -0.25495481,  0.0211663 ,  0.22125874, -0.06849229,\n",
       "         0.28984599,  0.3299989 , -0.29009042, -0.06759966,  0.19380159,\n",
       "        -0.0596489 ,  0.10649639,  0.30445249, -0.33391596,  0.05489561],\n",
       "       [-0.26271666, -0.26724865,  0.05284269,  0.05904358, -0.32659192,\n",
       "        -0.29730274,  0.17858387, -0.06465646,  0.12117587, -0.04586936,\n",
       "         0.0868853 , -0.13746304,  0.10931272, -0.26113159, -0.44279561,\n",
       "        -0.26477567, -0.11857589,  0.17707548,  0.07097753, -0.14081806,\n",
       "         0.04486566,  0.43195783, -0.26020249,  0.19283233,  0.13720245,\n",
       "        -0.14781701, -0.30565927, -0.0639891 ,  0.15807436, -0.04411886],\n",
       "       [-0.38778027, -0.22519103,  0.11083528,  0.08495731, -0.31023864,\n",
       "        -0.05853486,  0.28143356,  0.31030629,  0.09936572,  0.03102176,\n",
       "         0.27145985,  0.21267631,  0.24388134,  0.26981302, -0.05659536,\n",
       "        -0.28840828,  0.19163209, -0.05779243, -0.1602934 , -0.23963916,\n",
       "         0.25433864,  0.27770504,  0.14272162,  0.27395927, -0.05625922,\n",
       "        -0.12938399, -0.28497961,  0.10945144, -0.31249996, -0.01494983],\n",
       "       [ 0.0693913 , -0.1509893 ,  0.2453764 ,  0.05830608,  0.13026971,\n",
       "         0.06504248,  0.07430747,  0.1573726 ,  0.0822237 , -0.34154129,\n",
       "         0.15301172, -0.33487709,  0.13664354,  0.04904693,  0.15767771,\n",
       "        -0.15295466, -0.15541744, -0.17596355, -0.19220379, -0.17434887,\n",
       "         0.1879508 ,  0.23002821, -0.15305573, -0.31428755, -0.06421176,\n",
       "         0.22025588, -0.23287112,  0.32194811, -0.34307847,  0.07001601],\n",
       "       [-0.20294842,  0.02431808, -0.02366783,  0.10914521, -0.1544646 ,\n",
       "        -0.17137485, -0.23176615,  0.37111927,  0.02558952, -0.12554763,\n",
       "         0.23283389, -0.28242143,  0.11209616,  0.13578293,  0.1542184 ,\n",
       "        -0.01806205, -0.17118296,  0.26119871, -0.28158484, -0.13072295,\n",
       "         0.0360024 ,  0.15889526, -0.06397129,  0.25511398,  0.02888846,\n",
       "         0.23308792, -0.32907192,  0.31538776, -0.13329762,  0.41734745],\n",
       "       [ 0.22770009,  0.18881741, -0.06135946, -0.28841221, -0.19375399,\n",
       "         0.29352243, -0.2579222 , -0.25841848, -0.0119688 ,  0.27208601,\n",
       "        -0.15736795, -0.01287936,  0.01505247,  0.02400184, -0.09425805,\n",
       "        -0.19547175,  0.27568808,  0.13012336, -0.13043134, -0.32546618,\n",
       "         0.31858508,  0.23722906,  0.05409022,  0.19769713,  0.25038225,\n",
       "         0.19731561, -0.28152607,  0.07350252, -0.03809332, -0.13610742],\n",
       "       [ 0.02115136,  0.175258  ,  0.32760475, -0.09818076, -0.16180916,\n",
       "        -0.01135037, -0.10936253,  0.24007181, -0.26726929, -0.25265317,\n",
       "        -0.12488618,  0.20377437,  0.11450157, -0.27144722, -0.21906556,\n",
       "         0.29870737,  0.21881337,  0.20561164,  0.18125192,  0.11963608,\n",
       "         0.00950174,  0.43752302, -0.03394166,  0.00708424, -0.21245854,\n",
       "         0.03048855, -0.04953975,  0.32006497, -0.12878543,  0.04608292],\n",
       "       [ 0.03064916, -0.26131648,  0.12917479,  0.11345287, -0.00096881,\n",
       "         0.1835793 ,  0.13620145, -0.16206991, -0.15021762, -0.33939796,\n",
       "         0.0244212 , -0.02486562,  0.35744257,  0.04804844,  0.13138439,\n",
       "         0.05056822,  0.10645117, -0.01962005, -0.31552623, -0.20049872,\n",
       "         0.34643624,  0.24695894, -0.09292646, -0.32199047, -0.17217705,\n",
       "         0.19110513, -0.10708181,  0.16275187, -0.04884149,  0.18497167],\n",
       "       [ 0.11557067, -0.11191548,  0.3589242 ,  0.23518336,  0.09643811,\n",
       "        -0.05232796, -0.1624165 ,  0.29542734,  0.10057077,  0.09517044,\n",
       "         0.41551808, -0.1506219 ,  0.15910154,  0.12593725, -0.18036651,\n",
       "        -0.20321026, -0.15279051,  0.08733622, -0.10583007, -0.05825513,\n",
       "         0.25298215,  0.11837379, -0.1925628 , -0.04676166,  0.13957928,\n",
       "        -0.137689  , -0.18730746, -0.03129239,  0.20253332,  0.1037113 ],\n",
       "       [-0.19364733, -0.12701218,  0.23983646, -0.00884055, -0.25860134,\n",
       "         0.2380193 , -0.20718155, -0.14941544, -0.17441728, -0.2866828 ,\n",
       "        -0.12027706, -0.33261859,  0.17438947, -0.04093947, -0.02200126,\n",
       "        -0.006475  ,  0.33771291, -0.23726323,  0.08508046,  0.18464822,\n",
       "         0.20288315, -0.05747215, -0.07185892,  0.11812503, -0.3039549 ,\n",
       "         0.2193306 , -0.26423295,  0.02115119,  0.06143458,  0.21316252]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the coefficient values and interpret it\n",
    "\n",
    "coefficients = mlp.coefs_[0]\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00864307, -0.12179751,  0.00199165,  0.12632815, -0.19063782,\n",
       "       -0.05828515,  0.06638915,  0.0709988 , -0.31433613, -0.1099543 ,\n",
       "        0.07909943,  0.1116525 , -0.210572  , -0.14644128,  0.40757044,\n",
       "        0.14390508, -0.25824413, -0.06137398, -0.04668632,  0.17117016,\n",
       "       -0.15644084, -0.20505539,  0.07235976, -0.13391416,  0.15935218,\n",
       "       -0.0383094 , -0.09495383,  0.40421205,  0.29538941,  0.38537121])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the intercepts values and interpret it\n",
    "\n",
    "interprets = mlp.intercepts_[0]\n",
    "interprets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interprets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you understand from the two values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight determine the influence input data has on the output, and can prevent overfitting of the learning model.\n",
    "Bias provide the information to efficiently propagate forward the learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
