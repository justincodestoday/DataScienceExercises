{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/FoKB5Z5.png\" align=\"left\" width=\"300\" height=\"250\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Code: J620-002-4:2020 \n",
    "\n",
    "## Program Name: FRONT-END SOFTWARE DEVELOPMENT\n",
    "\n",
    "## Title : Exe22 - Bagging and Boosting Exercise\n",
    "\n",
    "#### Name: \n",
    "\n",
    "#### IC Number:\n",
    "\n",
    "#### Date : 20/7/2023\n",
    "\n",
    "#### Introduction : \n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion :\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Boosting Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: (https://www.datacamp.com/community/tutorials/ensemble-learning-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 699\n",
      "Number of attributes = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  \\\n",
       "0                  1                            2           1   \n",
       "1                  5                            7          10   \n",
       "2                  1                            2           2   \n",
       "3                  1                            3           4   \n",
       "4                  3                            2           1   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0                3                1        1      2  \n",
       "1                3                2        1      2  \n",
       "2                3                1        1      2  \n",
       "3                3                7        1      2  \n",
       "4                3                1        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', \n",
    "                   header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "data = data.drop(['Sample code'],axis=1)\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          4.417740                 3.134478                  3.207439   \n",
       "std           2.815741                 3.051459                  2.971913   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bland Chromatin  \\\n",
       "count         699.000000                   699.000000       699.000000   \n",
       "mean            2.806867                     3.216023         3.437768   \n",
       "std             2.855379                     2.214300         2.438364   \n",
       "min             1.000000                     1.000000         1.000000   \n",
       "25%             1.000000                     2.000000         2.000000   \n",
       "50%             1.000000                     2.000000         3.000000   \n",
       "75%             4.000000                     4.000000         5.000000   \n",
       "max            10.000000                    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses       Class  \n",
       "count       699.000000  699.000000  699.000000  \n",
       "mean          2.866953    1.589413    2.689557  \n",
       "std           3.053634    1.715078    0.951273  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Clump Thickness              699 non-null    int64 \n",
      " 1   Uniformity of Cell Size      699 non-null    int64 \n",
      " 2   Uniformity of Cell Shape     699 non-null    int64 \n",
      " 3   Marginal Adhesion            699 non-null    int64 \n",
      " 4   Single Epithelial Cell Size  699 non-null    int64 \n",
      " 5   Bare Nuclei                  699 non-null    object\n",
      " 6   Bland Chromatin              699 non-null    int64 \n",
      " 7   Normal Nucleoli              699 non-null    int64 \n",
      " 8   Mitoses                      699 non-null    int64 \n",
      " 9   Class                        699 non-null    int64 \n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1      10\n",
       "2       2\n",
       "3       4\n",
       "4       1\n",
       "       ..\n",
       "694     2\n",
       "695     1\n",
       "696     3\n",
       "697     4\n",
       "698     5\n",
       "Name: Bare Nuclei, Length: 699, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Bare Nuclei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1      10\n",
       "2       2\n",
       "3       4\n",
       "4       1\n",
       "       ..\n",
       "694     2\n",
       "695     1\n",
       "696     3\n",
       "697     4\n",
       "698     5\n",
       "Name: Bare Nuclei, Length: 699, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace('?',0, inplace=True)\n",
    "data['Bare Nuclei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame object into NumPy array otherwise you will not be able to impute\n",
    "values = data.values\n",
    "\n",
    "# Now impute it\n",
    "\n",
    "imputedData = imputer.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalizedData = scaler.fit_transform(imputedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification - necessary dependencies\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "bag_clf = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate the features from the labels\n",
    "X = data.drop(('Class'), axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(bag_clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9599378881987578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "num_trees = 70\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 Perform classification using the Titanic dataset using the classifiers that you already know (Dtree and RF)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2           1       3                              Miss. Laina Heikkinen   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4           0       3                            Mr. William Henry Allen   \n",
       "..        ...     ...                                                ...   \n",
       "882         0       2                               Rev. Juozas Montvila   \n",
       "883         1       1                        Miss. Margaret Edith Graham   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   \n",
       "885         1       1                               Mr. Karl Howell Behr   \n",
       "886         0       3                                 Mr. Patrick Dooley   \n",
       "\n",
       "        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0      male  22.0                        1                        0   7.2500  \n",
       "1    female  38.0                        1                        0  71.2833  \n",
       "2    female  26.0                        0                        0   7.9250  \n",
       "3    female  35.0                        1                        0  53.1000  \n",
       "4      male  35.0                        0                        0   8.0500  \n",
       "..      ...   ...                      ...                      ...      ...  \n",
       "882    male  27.0                        0                        0  13.0000  \n",
       "883  female  19.0                        0                        0  30.0000  \n",
       "884  female   7.0                        1                        2  23.4500  \n",
       "885    male  26.0                        0                        0  30.0000  \n",
       "886    male  32.0                        0                        0   7.7500  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing the entire Titanic dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "t_dataset = pd.read_csv(r'../data_samples2/titanic.csv')\n",
    "t_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop name column\n",
    "titanic_df = t_dataset.drop(('Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  Siblings/Spouses Aboard  \\\n",
       "0           0       3    1  22.0                        1   \n",
       "1           1       1    0  38.0                        1   \n",
       "2           1       3    0  26.0                        0   \n",
       "3           1       1    0  35.0                        1   \n",
       "4           0       3    1  35.0                        0   \n",
       "..        ...     ...  ...   ...                      ...   \n",
       "882         0       2    1  27.0                        0   \n",
       "883         1       1    0  19.0                        0   \n",
       "884         0       3    0   7.0                        1   \n",
       "885         1       1    1  26.0                        0   \n",
       "886         0       3    1  32.0                        0   \n",
       "\n",
       "     Parents/Children Aboard     Fare  \n",
       "0                          0   7.2500  \n",
       "1                          0  71.2833  \n",
       "2                          0   7.9250  \n",
       "3                          0  53.1000  \n",
       "4                          0   8.0500  \n",
       "..                       ...      ...  \n",
       "882                        0  13.0000  \n",
       "883                        0  30.0000  \n",
       "884                        2  23.4500  \n",
       "885                        0  30.0000  \n",
       "886                        0   7.7500  \n",
       "\n",
       "[887 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode categorical data into numerical value\n",
    "from sklearn import preprocessing\n",
    "\n",
    "new_sex = {'male': 1, 'female': 0}\n",
    "titanic_df['Sex'] = titanic_df['Sex'].replace(new_sex)\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the cleaned dataset\n",
    "t_df = titanic_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.      1.     22.      1.      0.      7.25  ]\n",
      " [ 1.      0.     38.      1.      0.     71.2833]\n",
      " [ 3.      0.     26.      0.      0.      7.925 ]\n",
      " ...\n",
      " [ 3.      0.      7.      1.      2.     23.45  ]\n",
      " [ 1.      1.     26.      0.      0.     30.    ]\n",
      " [ 3.      1.     32.      0.      0.      7.75  ]]\n",
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1\n",
      " 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0\n",
      " 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#define dependent variable and independent variable\n",
    "X = t_df.drop(('Survived'), axis=1)\n",
    "y = t_df.Survived\n",
    "\n",
    "print(X.values)\n",
    "print(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into the Training and the Test set. Set the test set to 0.3\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 1 0]\n",
      "Accuracy: 0.7790262172284644\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree object\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(y_pred)\n",
    "print(\"Accuracy:\", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0\n",
      " 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0\n",
      " 1 0 1 1 0 0 1 0]\n",
      "[0.41       0.59       0.84       0.16       0.94       0.06\n",
      " 1.         0.         0.96       0.04       0.44       0.56\n",
      " 0.72       0.28       1.         0.         0.4        0.6\n",
      " 0.59       0.41       0.19       0.81       0.07       0.93\n",
      " 0.43       0.57       0.96       0.04       0.59       0.41\n",
      " 0.95183333 0.04816667 1.         0.         0.01       0.99\n",
      " 0.793      0.207      0.8095     0.1905     0.94       0.06\n",
      " 0.1        0.9        0.65       0.35       0.77       0.23\n",
      " 0.86       0.14       0.89       0.11       0.99       0.01\n",
      " 0.85       0.15       0.84       0.16       0.76       0.24\n",
      " 0.44       0.56       0.73       0.27       0.47       0.53\n",
      " 0.75       0.25       0.1        0.9        0.81       0.19\n",
      " 0.92       0.08       0.24       0.76       0.         1.\n",
      " 0.06       0.94       0.07       0.93       1.         0.\n",
      " 0.         1.         0.99       0.01       0.91       0.09\n",
      " 0.94       0.06       0.84       0.16       0.99       0.01\n",
      " 0.95       0.05       0.96       0.04       0.98       0.02\n",
      " 0.93       0.07       0.73666667 0.26333333 1.         0.\n",
      " 0.17       0.83       0.8255     0.1745     0.37       0.63\n",
      " 0.15       0.85       0.16       0.84       0.23       0.77\n",
      " 0.93       0.07       0.21       0.79       0.94       0.06\n",
      " 0.03       0.97       0.65       0.35       0.93666667 0.06333333\n",
      " 0.97       0.03       0.14       0.86       0.91483333 0.08516667\n",
      " 0.99       0.01       0.65333333 0.34666667 0.02       0.98\n",
      " 0.16       0.84       0.99       0.01       0.57333333 0.42666667\n",
      " 0.1        0.9        0.04       0.96       0.59       0.41\n",
      " 0.01       0.99       0.99       0.01       0.99       0.01\n",
      " 0.99       0.01       0.96       0.04       0.97       0.03\n",
      " 0.06       0.94       0.04       0.96       0.63       0.37\n",
      " 0.97       0.03       0.65333333 0.34666667 0.85       0.15\n",
      " 0.2325     0.7675     0.2        0.8        0.95333333 0.04666667\n",
      " 0.17       0.83       0.89166667 0.10833333 0.32       0.68\n",
      " 1.         0.         1.         0.         0.03       0.97\n",
      " 0.06       0.94       0.85       0.15       0.96533333 0.03466667\n",
      " 0.39       0.61       0.02       0.98       1.         0.\n",
      " 1.         0.         0.71       0.29       0.41       0.59\n",
      " 0.95       0.05       0.82       0.18       0.04       0.96\n",
      " 0.8185     0.1815     1.         0.         0.8        0.2\n",
      " 0.88845238 0.11154762 0.95166667 0.04833333 0.55       0.45\n",
      " 0.4525     0.5475     0.87       0.13       0.7255     0.2745\n",
      " 0.44       0.56       0.86533333 0.13466667 0.67       0.33\n",
      " 0.96       0.04       0.34       0.66       0.91       0.09\n",
      " 0.86       0.14       0.         1.         0.02       0.98\n",
      " 0.11       0.89       0.85       0.15       0.26       0.74\n",
      " 0.9485     0.0515     0.91666667 0.08333333 0.93004762 0.06995238\n",
      " 0.66       0.34       0.96       0.04       0.97       0.03\n",
      " 0.92       0.08       0.8185     0.1815     0.04       0.96\n",
      " 0.99       0.01       0.29       0.71       0.76       0.24\n",
      " 0.43       0.57       0.04       0.96       0.92       0.08\n",
      " 0.7585     0.2415     0.97       0.03       0.98       0.02\n",
      " 0.95       0.05       0.05       0.95       0.68       0.32\n",
      " 0.94       0.06       0.82       0.18       0.18       0.82\n",
      " 0.91333333 0.08666667 0.04       0.96       0.28       0.72\n",
      " 0.985      0.015      0.99       0.01       0.29       0.71\n",
      " 0.99       0.01       0.57       0.43       0.95       0.05\n",
      " 0.09       0.91       0.81       0.19       0.03       0.97\n",
      " 0.96       0.04       0.08       0.92       0.04       0.96\n",
      " 0.04       0.96       0.43588095 0.56411905 0.97       0.03\n",
      " 0.58       0.42       0.28       0.72       0.22       0.78\n",
      " 0.99       0.01       0.72059524 0.27940476 0.91       0.09\n",
      " 0.68       0.32       0.         1.         0.1        0.9\n",
      " 1.         0.         0.05416667 0.94583333 0.49       0.51\n",
      " 1.         0.         0.94       0.06       0.8        0.2\n",
      " 0.77       0.23       0.93       0.07       0.02       0.98\n",
      " 0.99       0.01       0.95166667 0.04833333 0.11       0.89\n",
      " 0.93       0.07       0.55       0.45       0.9        0.1\n",
      " 0.03       0.97       0.62166667 0.37833333 0.02       0.98\n",
      " 0.02       0.98       0.15       0.85       0.96       0.04\n",
      " 0.88416667 0.11583333 0.75       0.25       0.7705     0.2295\n",
      " 1.         0.         0.         1.         0.78       0.22\n",
      " 0.64       0.36       0.82       0.18       0.91       0.09\n",
      " 0.09       0.91       0.         1.         1.         0.\n",
      " 0.8        0.2        0.78       0.22       0.15       0.85\n",
      " 0.76       0.24       0.89       0.11       0.98       0.02\n",
      " 1.         0.         0.65333333 0.34666667 0.93       0.07\n",
      " 0.76       0.24       1.         0.         0.925      0.075\n",
      " 1.         0.         0.97       0.03       0.89       0.11\n",
      " 0.71       0.29       0.35       0.65       0.55       0.45\n",
      " 0.18830952 0.81169048 0.37       0.63       0.4955     0.5045\n",
      " 0.37       0.63       0.96       0.04       0.7255     0.2745\n",
      " 0.7        0.3        0.84       0.16       0.51       0.49\n",
      " 0.14       0.86       0.9975     0.0025     0.26       0.74\n",
      " 1.         0.         0.96533333 0.03466667 0.07       0.93\n",
      " 0.01       0.99       0.895      0.105      0.91733333 0.08266667\n",
      " 0.01       0.99       0.961      0.039      0.96       0.04\n",
      " 1.         0.         0.04       0.96       0.44       0.56\n",
      " 0.8255     0.1745     0.42       0.58       0.92       0.08\n",
      " 0.38       0.62       0.49       0.51       0.98       0.02\n",
      " 0.62       0.38       0.13       0.87       0.97       0.03      ]\n",
      "Accuracy: 0.7827715355805244\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fit on training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Actual class predictions\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(y_pred_rf)\n",
    "\n",
    "# Probabilities for each class\n",
    "probabilities = rf_clf.predict_proba(X_test)\n",
    "print(probabilities.flatten())\n",
    "\n",
    "acc_score_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy:\", acc_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 Perform classification using the Titanic dataset using the classifiers that you already know and with feature selection and dimension reduction. Which gives you the best result?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29874926 0.29350524]\n",
      "[0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0\n",
      " 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 1\n",
      " 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 1 0 1 1 0]\n",
      "Accuracy: 0.704119850187266\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "#PCA & Pick up from the point where dataset has been split\n",
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "#Decision Tree object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebuild analytical dataset & create a copy of the cleaned dataset\n",
    "titanic_df\n",
    "t_df = titanic_df.copy()\n",
    "\n",
    "#define dependent variable and independent variable\n",
    "X = t_df.drop(('Survived'), axis=1)\n",
    "y = t_df.Survived\n",
    "\n",
    "#Split the dataset into the Training and the Test set. Set the test set to 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7715355805243446\n"
     ]
    }
   ],
   "source": [
    "# RF Feature Selector\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a random forest classifier（10000 trees）\n",
    "rf_clf = RandomForestClassifier(n_estimators=10000)\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "selector = SelectFromModel(rf_clf, threshold = 0.15)\n",
    "\n",
    "# Train the selector\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "important_feature_indices = selector.get_support(indices=True)\n",
    "important_feature_names = X.columns[important_feature_indices]\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "new_rf_clf = RandomForestClassifier(n_estimators=10000)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "X = t_df[important_feature_names]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "new_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Apply The Limited Classifier To The Test Data\n",
    "y_pred = new_rf_clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Perform classification using the Titanic dataset using bagging and boosting (choose 1 bagging and 1 boosting algo)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 122, in __call__\n",
      "    with config_context(**config):\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\contextlib.py\", line 281, in helper\n",
      "    return _GeneratorContextManager(func, args, kwds)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\contextlib.py\", line 103, in __init__\n",
      "    self.gen = func(*args, **kwds)\n",
      "TypeError: config_context() got an unexpected keyword argument 'enable_metadata_routing'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_5324\\2567125116.py\", line 16, in <module>\n",
      "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    The target variable to try to predict in the case of\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    \"\"\"Convert type into human readable string.\"\"\"\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    key = \"train_%s\" % name\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\concurrent\\futures\\_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "TypeError: config_context() got an unexpected keyword argument 'enable_metadata_routing'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\ACER\\anaconda3\\envs\\python-dscourse\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(base_estimator=KNeighborsClassifier())\n",
    "\n",
    "titanic_df\n",
    "t_df = titanic_df.copy()\n",
    "\n",
    "#define dependent variable and independent variable\n",
    "X = t_df.drop(('Survived'), axis=1)\n",
    "y = t_df.Survived\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.797752808988764\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "#create a copy of the cleaned dataset\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "titanic_df\n",
    "t_df = titanic_df.copy()\n",
    "\n",
    "#define dependent variable and independent variable\n",
    "X = t_df.drop(('Survived'), axis=1)\n",
    "y = t_df.Survived\n",
    "\n",
    "#Split the dataset into the Training and the Test set. Set the test set to 0.3\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply Xgboost\n",
    "model = XGBClassifier()\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of all 3 approaches, which gives you the best result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
